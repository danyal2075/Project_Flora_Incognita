{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e46dea-fb60-4b5c-82fb-196b28e5452d",
   "metadata": {},
   "source": [
    "\n",
    "Model_A : Batch_size = 512 , learning_rate = 1e-2\n",
    "Model_B : Batch_size = 256 , learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "164514ac-f6a8-41e1-9b2e-807498e2a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e9bca27-3d75-4542-8733-c82f214a3ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.150108342809128, 0.0021150332177026308)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# independent_test\n",
    "model_A_val_acc = [0.8340919435593992, 0.7541543364443433, 0.6667425449578875, 0.7587070339175962]\n",
    "model_B_val_acc = [0.9465179790623578, 0.9034828135670385, 0.9747325290234464, 0.9763259731390849]\n",
    "t_val_ind,p_val_ind = stats.ttest_ind(model_A_val_acc,model_B_val_acc)\n",
    "t_val_ind,p_val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6a5dfca-0765-4f5b-a022-86502cd6ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a statistically significant difference between the models.\n",
      "Model B performs better than Model A.\n"
     ]
    }
   ],
   "source": [
    "mean_A = np.mean(model_A_val_acc)\n",
    "mean_B = np.mean(model_B_val_acc)\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "if p_val_ind < alpha:\n",
    "    print(\"There is a statistically significant difference between the models.\")\n",
    "    \n",
    "    if mean_A > mean_B:\n",
    "        print(\"Model A performs better than Model B.\")\n",
    "    else:\n",
    "        print(\"Model B performs better than Model A.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the models.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559d327-3c81-4710-b5b3-e747ae64c5ce",
   "metadata": {},
   "source": [
    "f the p-value is less than 0.05, then you can conclude that the difference in the means of the two groups is statistically significant. In this case, you can conclude that the model with the higher mean score is the better model. means find the mean of the all kfold split for 2 models using validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916de97-8426-4d04-92fb-c40b5554358b",
   "metadata": {},
   "source": [
    "# normality test : shapiro wilk test\n",
    "The Shapiro–Wilk test is essentially a goodness-of-fit test. That is, it examines how close the sample data fit to a normal distribution. It does this by ordering and standardizing the sample (standardizing refers to converting the data to a distribution with mean μ = 0 and standard deviation σ = 1 ).\n",
    "How does Shapiro-Wilk test show normality?\n",
    "The Shapiro-Wilk test is a statistical test of the hypothesis that the distribution of the data as a whole deviates from a comparable normal distribution. If the test is non-significant (p>. 05) it tells us that the distribution of the sample is not significantly different from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab4d6c3-4b19-4ac4-abef-6098b9afad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9539754986763, pvalue=0.7410178184509277)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(model_A_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a9c89fe-9717-4344-9b12-d0eb3e282386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.8614342212677002, pvalue=0.2653777003288269)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(model_B_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7987439-8011-4e8c-a63d-4499b3620323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedianTestResult(statistic=4.5, pvalue=0.033894853524689295, median=0.8687873785632189, table=array([[0, 4],\n",
       "       [4, 0]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.median_test(model_A_val_acc,model_B_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c55ba-b5b5-4f75-a5f4-a8e58cc432ff",
   "metadata": {},
   "source": [
    "if the median_test and student test are ok( e.g p = 1:incase of median_test, and p_value > 0.01). then its fine both are performing well.\n",
    "if upper tests are not ok. then we apply shapiro test to see the noramlity test to see which one performs better.\n",
    "if t-test pvalue is|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60255d3-b40f-4987-84d5-fb866b103ffc",
   "metadata": {},
   "source": [
    "<!-- Monday\n",
    "Model_A : Batch_size = 512 , learning_rate = 1e-2\n",
    "Model_B : Batch_size = 256 , learning_rate = 1e-3 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80771b0e-ab38-4e15-98eb-3217ce751b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.150108342809128, 0.0021150332177026308)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A_val_acc_m = [0.7878925807919891, 0.8754837241065331, 0.7776007284315957, 0.7318461188254041]\n",
    "model_B_val_acc_m = [0.9913518434228493, 0.9883906214432051, 0.9920327794218075, 0.9899840655588437]\n",
    "t_val_ind,p_val_ind = stats.ttest_ind(model_A_val_acc,model_B_val_acc)\n",
    "t_val_ind,p_val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9d332ad-9387-426d-83e5-4d42f106c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a statistically significant difference between the models.\n",
      "Model B performs better than Model A.\n"
     ]
    }
   ],
   "source": [
    "mean_A = np.mean(model_A_val_acc_m)\n",
    "mean_B = np.mean(model_B_val_acc_m)\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "if p_val_ind < alpha:\n",
    "    print(\"There is a statistically significant difference between the models.\")\n",
    "    \n",
    "    if mean_A > mean_B:\n",
    "        print(\"Model A performs better than Model B.\")\n",
    "    else:\n",
    "        print(\"Model B performs better than Model A.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26a818f8-c87b-48b6-916b-ce2a0ab66c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9333312511444092, pvalue=0.6141136288642883)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(model_A_val_acc_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9019784c-72e2-4ac8-851f-3c88ed76c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9588672518730164, pvalue=0.7717805504798889)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(model_B_val_acc_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18a3bf67-3258-4887-8369-31d39454f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedianTestResult(statistic=4.5, pvalue=0.033894853524689295, median=0.9319371727748691, table=array([[0, 4],\n",
       "       [4, 0]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.median_test(model_A_val_acc_m,model_B_val_acc_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538a2b3-7456-4dd7-bda8-d4f314731e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensorflow]",
   "language": "python",
   "name": "conda-env-.conda-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
