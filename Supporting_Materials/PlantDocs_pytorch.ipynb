{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1595cae-f851-4fc6-8b67-a78aa6e76d4a",
   "metadata": {},
   "source": [
    "**Use of ResNet18 on pre-trained is False**\n",
    "- ImageFolder('path_to_data', 'transform_instance'): to load the images from folder having seperate folder for each class\n",
    "- transform.compose(): pass list of Augmentation tech. \n",
    "- Normalization: Code is written for to find out data std and mean\n",
    "- DataLoade('imagefolder_instance', batch_size, shuffle) \n",
    "- Training on smaller dataset using random_split(dataset, [training_size, test_size]).\n",
    "- \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d5f9e5b-82ca-4868-beb1-123cb8d1eb42",
   "metadata": {},
   "source": [
    "#Splitting data\n",
    "train_set, val_set = torch.utils.data.random_split(train_datasets, [train_data, testing_data])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8fc6619-ea72-4f30-8132-a63549ec93dd",
   "metadata": {},
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience):\n",
    "        self.pateince  = patience\n",
    "        self.best_score = None\n",
    "        self.counter = None\n",
    "        self.stop  = False\n",
    "    def _stopping(self,val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss > self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.counter == self.pateince:\n",
    "                self.stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            print(self.best_score)\n",
    "            counter = 0\n",
    "**************\n",
    "earlystopping = EarlyStopping(patience=3)\n",
    "Training model\n",
    "validation model\n",
    "earlystopping._stopping(val_loss)\n",
    "    if earlystopping.stop:\n",
    "        print('Early Stopping Excuated')\n",
    "        break\n",
    "  \n",
    "  \n",
    "then print accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4782a0-c589-448a-8d0c-6e6542467169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e110448-5ec3-4958-9f7a-32f849ef2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'NewPlantDiease/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)'\n",
    "train_data1 = path + '/train'\n",
    "val_data1 = path + '/valid'\n",
    "diease = os.listdir(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2aff6f5-59fb-4164-8e60-69ebcb1abb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, testing_data  = train_test_split(train_data1, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641183f8-e485-4c75-b93d-5a6a2a59f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = [0.4757, 0.5001, 0.4264]\n",
    "# std = [0.2165, 0.1957, 0.2320]\n",
    "# transforms = transform.Compose([transform.Resize((256, 256)), transform.ToTensor(), transform.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f1b5ef-325b-48ee-9f48-e6283bfec608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datasets = ImageFolder(root = train_data1, transform=transforms)\n",
    "# LEN_TRAIN = len(train_datasets)\n",
    "# # LEN_val = len(val_datasets)\n",
    "# print(LEN_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd9bfa0d-86e5-4ece-8b6c-e03776472eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_data, testing_data  = train_test_split(train_data1, test_size = 0.3, random_state=42)\n",
    "# # len(train_data), len(testing_data)\n",
    "# train_data = int(0.9 * LEN_TRAIN)\n",
    "# testing_data = LEN_TRAIN - train_data\n",
    "# train_set, val_set = torch.utils.data.random_split(train_datasets, [train_data, testing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1945b7-d30e-49e2-b795-3a4f753f296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validation_set = val_set.dataset\n",
    "# len(validation_set.classes),len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf62d0c-bb11-4957-b8aa-a8c2ff1a4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_dataloader = DataLoader(dataset = val_set,  batch_size= 256, shuffle = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0330325a-7eb8-4d85-b9a9-70a28dbc3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_datasets = ImageFolder(root = val_data1, transform=transforms)\n",
    "# train_data1 = int(0.8 * len(val_datasets))\n",
    "# testing_data1 = len(val_datasets) - train_data1\n",
    "# train_set1, val_set1 = torch.utils.data.random_split(val_datasets, [train_data1, testing_data1])\n",
    "# Val_dataloader = DataLoader(dataset = val_set1,  batch_size= 256, shuffle = False )\n",
    "# validation_set1 = Val_dataloader.dataset\n",
    "# len(validation_set.classes),len(val_set1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437bd21b-7d80-4a16-98bd-24a049585b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.4757, 0.5001, 0.4264]\n",
    "std = [0.2165, 0.1957, 0.2320]\n",
    "transforms = transform.Compose([transform.Resize((256, 256)), transform.ToTensor(), transform.Normalize(mean=mean, std=std)])\n",
    "train_datasets = ImageFolder(root = train_data1, transform=transforms)\n",
    "val_datasets = ImageFolder(root = val_data1, transform=transforms)\n",
    "Train_dataloader = DataLoader(dataset = train_datasets,  batch_size= 256, shuffle = True )\n",
    "Val_dataloader = DataLoader(dataset = val_datasets,  batch_size= 256, shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a083147d-d004-48ac-99ce-df273bc5ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70295 17572\n"
     ]
    }
   ],
   "source": [
    "LEN_TRAIN = len(train_datasets)\n",
    "LEN_val = len(val_datasets)\n",
    "print(LEN_TRAIN, LEN_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a0a746-f245-45af-988f-66bbd4883ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEN_TRAIN = len(testing_data)\n",
    "# # LEN_val = len(val_datasets)\n",
    "# print(LEN_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "175e9f24-f637-4159-bc00-0b93c311301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(testing_data))\n",
    "# print(images.size())\n",
    "# # Access the first image and label\n",
    "# first_image = images[2]\n",
    "# first_label = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74dbe45-5714-436d-bd31-d7277b310ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7c279bf-ac78-40be-b8c3-1dd3165eb8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "model = models.resnet18(pretrained=True)\n",
    "# model\n",
    "# Freeze all parameters in the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# # Extracting features from last CNN layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features , 38)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1c2b32-56a1-412d-98ce-047a9276140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss function\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482a025a-3395-4240-96e0-0c4f546efdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:43<00:00, 11.50s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Test_Loss: 0.6949630379676819,Validation_loss: 0.576035737991333, Train_acc: 0.6622092609716196, Val_acc: 0.930286819940815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:11<00:00, 11.39s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test_Loss: 0.22621706128120422,Validation_loss: 0.1537151038646698, Train_acc: 0.9567110036275696, Val_acc: 0.9691554746187115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:26<00:00, 11.44s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Test_Loss: 0.09995708614587784,Validation_loss: 0.06422144174575806, Train_acc: 0.9785333238494914, Val_acc: 0.9787161393125426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:20<00:00, 11.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Test_Loss: 0.059015363454818726,Validation_loss: 0.03865286707878113, Train_acc: 0.9868127178319938, Val_acc: 0.9840655588436148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:42<00:00, 11.50s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Test_Loss: 0.053242675960063934,Validation_loss: 0.027214733883738518, Train_acc: 0.9917775090689238, Val_acc: 0.9877646255406328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:32<00:00, 11.46s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Test_Loss: 0.031716253608465195,Validation_loss: 0.022218959406018257, Train_acc: 0.9948218223202219, Val_acc: 0.9898133394035966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:36<00:00, 11.48s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Test_Loss: 0.02711004950106144,Validation_loss: 0.014745833352208138, Train_acc: 0.9965431396258624, Val_acc: 0.9912360573639881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [52:45<00:00, 11.51s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Test_Loss: 0.01818525791168213,Validation_loss: 0.014877483248710632, Train_acc: 0.9980510704886549, Val_acc: 0.9925449578875484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [56:57<00:00, 12.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Test_Loss: 0.011092079803347588,Validation_loss: 0.009810097515583038, Train_acc: 0.9986343267657728, Val_acc: 0.9938538584111086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 42/275 [10:31<58:25, 15.05s/batch]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m train_prob \u001b[38;5;241m=\u001b[39m model(xtrain)\n\u001b[1;32m     16\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_function(train_prob, ytrain)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update the model parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    start = time.time()\n",
    "    \n",
    "    tr_acc = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(Train_dataloader, unit=\"batch\") as tepoch:\n",
    "        for xtrain, ytrain in tepoch:\n",
    "            \n",
    "            train_prob = model(xtrain)\n",
    "        \n",
    "            \n",
    "            train_loss = loss_function(train_prob, ytrain)\n",
    "            train_loss.backward() # backpropagation\n",
    "\n",
    "            # loss.backward()\n",
    "            optimizer.step() # update the model parameters\n",
    "            optimizer.zero_grad()\n",
    "            # training ends\n",
    "            \n",
    "            train_pred = torch.max(train_prob, 1).indices\n",
    "            tr_acc += int(torch.sum(train_pred == ytrain))\n",
    "            \n",
    "        ep_tr_acc = tr_acc / LEN_TRAIN\n",
    "    end = time.time()\n",
    "    duration = (end - start) / 60\n",
    "    \n",
    "    # print(f\"Epoch: {epoch}, Test_Loss: {train_loss}, Train_acc: {ep_tr_acc}\")\n",
    "    # Evaluate\n",
    "    \n",
    "    model.eval()\n",
    "#     # with torch.no_grad():\n",
    "    with torch.no_grad():\n",
    "        for xval, yval in Val_dataloader:\n",
    "            val_prob = model(xval)\n",
    "            \n",
    "            val_loss = loss_function(val_prob , yval)\n",
    "            \n",
    "            val_pred = torch.max(val_prob,1).indices\n",
    "            val_acc += int(torch.sum(val_pred == yval))\n",
    "            \n",
    "        ep_val_acc = val_acc / LEN_val\n",
    "    \n",
    "    end = time.time()\n",
    "    duration = (end - start) / 60\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Test_Loss: {train_loss},Validation_loss: {val_loss}, Train_acc: {ep_tr_acc}, Val_acc: {ep_val_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c7541-ea01-4ba7-8d32-2570bd49346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
